<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FlexAttention for Efficient High-Resolution Vision-Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FlexAttention</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FlexAttention for Efficient High-Resolution Vision-Language Models</h1>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current high-resolution vision-language models encode images as high-resolution image tokens and exhaustively take all these tokens to compute attention, which significantly increases the computational cost. To address this problem, we propose FlexAttention, a flexible attention mechanism for efficient high-resolution vision-language models. Specifically, a high-resolution image is encoded both as high-resolution tokens and low-resolution tokens, where only the low-resolution tokens and a few selected high-resolution tokens are utilized to calculate the attention map, which greatly shrinks the computational cost. The high-resolution tokens are selected via a high-resolution selection module which could retrieve tokens of relevant regions based on an input attention map. The selected high-resolution tokens are then concatenated to the low-resolution tokens and text tokens, and input to a hierarchical self-attention layer which produces an attention map that could be used for the next-step high-resolution token selection. The hierarchical self-attention process and high-resolution token selection process are performed iteratively for each attention layer. Experiments on multimodal benchmarks prove that our FlexAttention outperforms existing high-resolution VLMs (e.g., relatively ~9% in V* Bench, ~7% in TextVQA), while also significantly reducing the computational cost by nearly 40%.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<div class="container is-max-desktop" id="method">
  <hr class="solid">
</div>



<section class="section" id="visualization">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Attention Map Visualization</h2>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
        <img src="static/assets/0.gif" alt="visualization" style="width:40%;">
    </div>
    <div class="columns is-centered">
      <p>
        Question: What is the brand of this camera?
        <br>
        Answer: Dakota digital
      </p>
    </div>
    <hr class="solid">
    <div class="columns is-centered has-text-centered">
      <img src="static/assets/40.gif" alt="visualization" style="width:40%;">
    </div>
    <div class="columns is-centered">
      <p>
        Question: What is the number on the runner in middle?
        <br>
        Answer: 57859
      </p>
    </div>
    <hr class="solid">
    <div class="columns is-centered has-text-centered">
      <img src="static/assets/69.gif" alt="visualization" style="width:40%;">
    </div>
    <div class="columns is-centered">
      <p>
        Question: Who wrote this book?
        <br>
        Answer: Ray Kurzweil
      </p>
    </div>
  </div>

</section>

<div class="container is-max-desktop" id="method">
  <hr class="solid">
</div>


<!-- Default Statcounter code for flexattention
https://flexattention.github.io/ -->
<script type="text/javascript">
  var sc_project=12978195; 
  var sc_invisible=1; 
  var sc_security="41250ae2"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="web counter"
  href="https://statcounter.com/" target="_blank"><img
  class="statcounter"
  src="https://c.statcounter.com/12978195/0/41250ae2/1/"
  alt="web counter"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>
</html>
